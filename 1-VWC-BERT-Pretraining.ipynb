{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 GPU(s) available.\n",
      "We will use the GPU: Tesla P100-PCIE-16GB\n",
      "cuda\n",
      "Cpu count:  20\n"
     ]
    }
   ],
   "source": [
    "import torch# If there's a GPU available...\n",
    "import random\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\" ##I will find a way to fix this later :(\n",
    "\n",
    "NUM_GPUS=0\n",
    "\n",
    "try:\n",
    "    if torch.cuda.is_available():  \n",
    "        device = torch.device(\"cuda\")\n",
    "        NUM_GPUS=torch.cuda.device_count()\n",
    "        print('There are %d GPU(s) available.' % NUM_GPUS)\n",
    "        print('We will use the GPU:', torch.cuda.get_device_name())# If not...\n",
    "    else:\n",
    "        print('No GPU available, using the CPU instead.')\n",
    "        device = torch.device(\"cpu\")  \n",
    "except:\n",
    "    print('Cuda error using CPU instead.')\n",
    "    device = torch.device(\"cpu\")  \n",
    "    \n",
    "print(device)\n",
    "\n",
    "# device = torch.device(\"cpu\")  \n",
    "# print(device)\n",
    "\n",
    "NUM_PROCESSORS=multiprocessing.cpu_count()\n",
    "print(\"Cpu count: \",NUM_PROCESSORS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specify Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading directory:  ./Results\n",
      "Model Saving directory: ./Results/NVD/Model/\n"
     ]
    }
   ],
   "source": [
    "from ipynb.fs.full.Dataset import getDataset, getDummyDataset, Data        \n",
    "\n",
    "DIR='./Results'\n",
    "    \n",
    "from pathlib import Path\n",
    "Path(DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DATASET_LOAD_DIR=\"./NVD/\"\n",
    "MODEL_SAVE_DIR=DIR+'/NVD/Model/'\n",
    "\n",
    "Path(MODEL_SAVE_DIR).mkdir(parents=True, exist_ok=True)\n",
    "print(\"Data loading directory: \", DIR)\n",
    "print(\"Model Saving directory:\", MODEL_SAVE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some more packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pathlib\n",
    "import zipfile\n",
    "import wget\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import functional as F\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import RandomSampler,SequentialSampler\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForMaskedLM\n",
    "from transformers import AutoConfig\n",
    "\n",
    "from transformers import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from pytorch_lightning.tuner.tuning import Tuner\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For reproduciblity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "# Set the seed value all over the place to make this reproducible.\n",
    "from random import sample\n",
    "\n",
    "seed_val = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(seed_val)\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "pl.seed_everything(seed_val)\n",
    "\n",
    "try:\n",
    "    torch.cuda.manual_seed(seed_val)\n",
    "    torch.cuda.manual_seed_all(seed_val)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "except:\n",
    "    print(\"nothing to set for cudnn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible choices for pretrained are:\n",
    "distilbert-base-uncased\n",
    "bert-base-uncased\n",
    "\n",
    "The BERT paper says: \"[The] pre-trained BERT model can be fine-tuned with just one additional output\n",
    "layer to create state-of-the-art models for a wide range of tasks, such as question answering and\n",
    "language inference, without substantial task-specific architecture modifications.\"\n",
    "\n",
    "Huggingface/transformers provides access to such pretrained model versions, some of which have been\n",
    "published by various community members.\n",
    "\n",
    "BertForSequenceClassification is one of those pretrained models, which is loaded automatically by\n",
    "AutoModelForSequenceClassification because it corresponds to the pretrained weights of\n",
    "\"bert-base-uncased\".\n",
    "\n",
    "Huggingface says about BertForSequenceClassification: Bert Model transformer with a sequence\n",
    "classification/regression head on top (a linear layer on top of the pooled output) e.g. for GLUE\n",
    "tasks.\"\n",
    "\n",
    "This part is easy  we instantiate the pretrained model (checkpoint)\n",
    "\n",
    "But it's also incredibly important, e.g. by using \"bert-base-uncased, we determine, that that model\n",
    "does not distinguish between lower and upper case. This might have a significant impact on model\n",
    "performance!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(pl.LightningModule):\n",
    "    def __init__(self,*args, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "        # a very useful feature of pytorch lightning  which leads to the named variables that are passed in\n",
    "        # being available as self.hparams.<variable_name> We use this when refering to eg\n",
    "        # self.hparams.learning_rate\n",
    "\n",
    "        # freeze\n",
    "        self._frozen = False\n",
    "\n",
    "        # eg https://github.com/stefan-it/turkish-bert/issues/5\n",
    "        config = AutoConfig.from_pretrained(self.hparams.pretrained,\n",
    "                                            output_attentions=False,\n",
    "                                            output_hidden_states=False)\n",
    "\n",
    "        #print(config)\n",
    "\n",
    "        A = AutoModelForMaskedLM\n",
    "        self.model = A.from_pretrained(self.hparams.pretrained, config=config)\n",
    "\n",
    "        print('Model: ', type(self.model))\n",
    "        \n",
    "\n",
    "    def forward(self, batch):\n",
    "        # there are some choices, as to how you can define the input to the forward function I prefer it this\n",
    "        # way, where the batch contains the input_ids, the input_put_mask and sometimes the labels (for\n",
    "        # training)\n",
    "        \n",
    "        #print(batch['input_ids'].shape)\n",
    "        #print(batch['labels'].shape)\n",
    "                \n",
    "        outputs = self.model(input_ids=batch['input_ids'],\n",
    "                        attention_mask=batch['attention_mask'],\n",
    "                        labels=batch['labels'])\n",
    "\n",
    "        loss = outputs[0]\n",
    "\n",
    "        return loss\n",
    "    \n",
    "#     def on_train_batch_start(self, batch, batch_idx, dataloader_idx):\n",
    "#         self.t2=time.time()\n",
    "    \n",
    "#     def on_train_epoch_start(self):\n",
    "#         self.t0=time.time()\n",
    "    \n",
    "    \n",
    "#     def on_train_batch_end(self, outputs, batch, batch_idx, dataloader_idx):\n",
    "        \n",
    "#         if batch_idx%50 ==0:\n",
    "#             t1=time.time()        \n",
    "#             #print(\"Batch {0} of {1}: {2:.6f}\".format(batch_idx+1, self.total_train_batches, t1-self.t0))\n",
    "#             print(\"Batch {0}: {1:.4f}\".format(batch_idx, t1-self.t0))\n",
    "    \n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # the training step is a (virtual) method,specified in the interface, that the pl.LightningModule\n",
    "        # class stipulates you to overwrite. This we do here, by virtue of this definition\n",
    "        \n",
    "        # self refers to the model, which in turn acceses the forward method\n",
    "        loss = self(batch)\n",
    "        \n",
    "        #tensorboard_logs = {'train_loss': loss}\n",
    "        # pytorch lightning allows you to use various logging facilities, eg tensorboard with tensorboard we\n",
    "        # can track and easily visualise the progress of training. In this case\n",
    "        \n",
    "        self.log('loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        #self.log('train_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        \n",
    "        #return {'loss': loss, 'log': tensorboard_logs}\n",
    "        # the training_step method expects a dictionary, which should at least contain the loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        val_loss = self(batch)\n",
    "        self.log('val_loss', val_loss, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        return val_loss\n",
    "        \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        test_loss = self(batch)\n",
    "        self.log('test_loss', test_loss, on_epoch=True, prog_bar=True)\n",
    "        \n",
    "        return test_loss\n",
    "    \n",
    "#     def on_train_epoch_end(self, train_step_outputs):\n",
    "#         print('Epoch ',self.current_epoch,' done: took ',time.time()-self.t0, ' sec')\n",
    "\n",
    "        #---------------------        \n",
    "#         print(train_step_outputs)        \n",
    "#         import pdb; pdb.set_trace()\n",
    "\n",
    "#         avg_loss = torch.stack([x['loss'] for x in train_step_outputs]).mean()\n",
    "    \n",
    "#         print(torch.stack([x['loss'] for x in train_step_outputs]))\n",
    "#         tensorboard_logs = {'train_loss': avg_loss}\n",
    "        \n",
    "#         self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "#         self.log('log', tensorboard_logs, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        \n",
    "#         return {\n",
    "#             'train_loss': avg_loss,\n",
    "#             'log': tensorboard_logs,\n",
    "#             'progress_bar': {\n",
    "#                 'train_loss': avg_loss\n",
    "#             }\n",
    "#         }\n",
    "#---------------------\n",
    "\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        # The configure_optimizers is a (virtual) method, specified in the interface, that the\n",
    "        # pl.LightningModule class wants you to overwrite.\n",
    "        # In this case we define that some parameters are optimized in a different way than others. In\n",
    "        # particular we single out parameters that have 'bias', 'LayerNorm.weight' in their names. For those\n",
    "        # we do not use an optimization technique called weight decay.\n",
    "\n",
    "        no_decay = ['bias', 'LayerNorm.weight']\n",
    "\n",
    "        optimizer_grouped_parameters = [{\n",
    "            'params': [\n",
    "                p for n, p in self.named_parameters()\n",
    "                if not any(nd in n for nd in no_decay)\n",
    "            ],\n",
    "            'weight_decay':\n",
    "            0.01\n",
    "        }, {\n",
    "            'params': [\n",
    "                p for n, p in self.named_parameters()\n",
    "                if any(nd in n for nd in no_decay)\n",
    "            ],\n",
    "            'weight_decay':\n",
    "            0.0\n",
    "        }]\n",
    "        optimizer = AdamW(optimizer_grouped_parameters,\n",
    "                          lr=self.hparams.learning_rate,\n",
    "                          eps=1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                          )\n",
    "\n",
    "        \n",
    "        # We also use a scheduler that is supplied by transformers.\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=0, # Default value in run_glue.py\n",
    "            num_training_steps=self.hparams.num_training_steps)\n",
    "\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "#---------------------\n",
    "#     def freeze(self) -> None:\n",
    "#         # freeze all layers, except the final classifier layers\n",
    "#         for name, param in self.model.named_parameters():\n",
    "#             if 'classifier' not in name:  # classifier layer\n",
    "#                 param.requires_grad = False\n",
    "\n",
    "\n",
    "#         self._frozen = True\n",
    "\n",
    "#     def unfreeze(self) -> None:\n",
    "#         if self._frozen:\n",
    "#             for name, param in self.model.named_parameters():\n",
    "#                 if 'classifier' not in name:  # classifier layer\n",
    "#                     param.requires_grad = True\n",
    "\n",
    "#         self._frozen = False\n",
    "\n",
    "#     def on_epoch_start(self):\n",
    "#         \"\"\"pytorch lightning hook\"\"\"\n",
    "#         if self.current_epoch < self.hparams.nr_frozen_epochs:\n",
    "#             self.freeze()\n",
    "\n",
    "#         if self.current_epoch >= self.hparams.nr_frozen_epochs:\n",
    "#             self.unfreeze()\n",
    "#---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data class definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So here we finally arrive at the definition of our data class derived from pl.LightningDataModule.\n",
    "\n",
    "In earlier versions of pytorch lightning  (prior to 0.9) the methods here were part of the model class\n",
    "derived from pl.LightningModule. For better flexibility and readability the Data and Model related parts\n",
    "were split out into two different classes:\n",
    "\n",
    "pl.LightningDataModule and pl.LightningModule\n",
    "\n",
    "with the Model related part remaining in pl.LightningModule\n",
    "\n",
    "This is explained in more detail in this video: https://www.youtube.com/watch?v=L---MBeSXFw\n",
    "```\n",
    "class CDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        \n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "```\n",
    "\n",
    "\n",
    "Another testing code\n",
    "\n",
    "```\n",
    "class CDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, collator, labels):\n",
    "        self.encodings = encodings\n",
    "        self.collator = collator\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}        \n",
    "        item = self.collator([item])\n",
    "        item = {key: val[0] for key, val in item.items()}\n",
    "    \n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "A=AutoTokenizer\n",
    "berttokenizer=A.from_pretrained('bert-base-uncased')\n",
    "datacollator=DataCollatorForLanguageModeling(tokenizer=berttokenizer,mlm_probability=0.15, mlm=True)\n",
    "\n",
    "data, sentences, labels = getDummyDataset()\n",
    "\n",
    "train_encodings = berttokenizer(sentences, truncation=True, padding=True)\n",
    "\n",
    "dataset = CDataset(train_encodings,datacollator)\n",
    "\n",
    "dataset[0]\n",
    "```\n",
    "\n",
    "cf this open issue: https://github.com/PyTorchLightning/pytorch-lightning/issues/3232"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels, collator):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "        self.collator = collator\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}            \n",
    "        item = self.collator([item])\n",
    "        item = {key: val[0] for key, val in item.items()}\n",
    "    \n",
    "        if type(self.labels)!=torch.Tensor:\n",
    "            item['org_labels']= torch.tensor(self.labels[idx])\n",
    "        else:\n",
    "            item['org_labels']= self.labels[idx]\n",
    "    \n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "\n",
    "class DataProcessing(pl.LightningDataModule):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "#         self.save_hyperparameters()\n",
    "        if isinstance(args, tuple): args = args[0]\n",
    "        self.hparams = args\n",
    "        self.batch_size=self.hparams.batch_size        \n",
    "\n",
    "#         print('args:', args)\n",
    "#         print('kwargs:', kwargs)\n",
    "#         print(f'self.hparams.pretrained:{self.hparams.pretrained}')\n",
    "\n",
    "        #print('Loading BERT tokenizer')\n",
    "        print(f'PRETRAINED:{self.hparams.pretrained}')\n",
    "\n",
    "        A = AutoTokenizer\n",
    "        self.tokenizer = A.from_pretrained(self.hparams.pretrained, use_fast=True)\n",
    "\n",
    "        print('Tokenizer:', type(self.tokenizer))\n",
    "        \n",
    "        self.datacollator=DataCollatorForLanguageModeling(tokenizer=self.tokenizer, mlm_probability=0.15)\n",
    "\n",
    "        \n",
    "    def setup(self, stage=None):\n",
    "        \n",
    "        MAX_TEXT_LENGTH=512\n",
    "    \n",
    "#         CVE dataset\n",
    "#         ------------------------------------        \n",
    "        data, df_CVE, df_CWE=None,None,None\n",
    "    \n",
    "        if self.hparams.rand_dataset=='dummy':            \n",
    "            #------------------------------------\n",
    "            data, sentences, labels = getDummyDataset()        \n",
    "            #------------------------------------\n",
    "        else:        \n",
    "            if self.hparams.rand_dataset=='temporal':\n",
    "                print(\"Temporal Partition:--\")\n",
    "                data, df_CVE, df_CWE = getDataset(DATASET_LOAD_DIR)            \n",
    "            else:\n",
    "                print(\"Random Partition:--\")\n",
    "                data, df_CVE, df_CWE = getRandomDataset(DATASET_LOAD_DIR, 0.70, 0.10)\n",
    "\n",
    "            sentences=df_CVE['CVE Description'].apply(lambda x: x[:MAX_TEXT_LENGTH])\n",
    "            labels=data.y\n",
    "            CWE_IDS_USED=df_CWE['Name'].tolist()\n",
    "            INDEX_TO_CWE_MAP=dict(zip(list(range(len(CWE_IDS_USED))),CWE_IDS_USED))\n",
    "            CWE_TO_INDEX_MAP=dict(zip(CWE_IDS_USED,list(range(len(CWE_IDS_USED)))))\n",
    "            sentences=sentences.tolist()\n",
    "        \n",
    "        \n",
    "        if type(labels)!=torch.Tensor:\n",
    "            labels=torch.tensor(labels,dtype=torch.long)\n",
    "        else:\n",
    "            labels=labels.type(torch.LongTensor)\n",
    "        \n",
    "        self.NUM_CLASSES=len(data.y[0])\n",
    "    \n",
    "        train_encodings = self.tokenizer(sentences, truncation=True, padding=True, max_length=MAX_TEXT_LENGTH)        \n",
    "        self.dataset = CDataset(train_encodings, labels, self.datacollator)        \n",
    "        \n",
    "        val_mask= (data.val_mask == True).nonzero().flatten().numpy()\n",
    "        val_encodings = self.tokenizer([sentences[i] for i in val_mask], truncation=True, padding=True, max_length=MAX_TEXT_LENGTH)\n",
    "        self.val_dataset=CDataset(val_encodings, labels[data.val_mask], self.datacollator)\n",
    "        \n",
    "        test_mask= (data.test_mask == True).nonzero().flatten().numpy()\n",
    "        test_encodings = self.tokenizer([sentences[i] for i in test_mask], truncation=True, padding=True, max_length=MAX_TEXT_LENGTH)\n",
    "        self.test_dataset=CDataset(test_encodings, labels[data.test_mask], self.datacollator)\n",
    "                \n",
    "        #print('Example Sentence[0]: ', sentences[0])              \n",
    "    \n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        \n",
    "        train_sampler = RandomSampler(self.dataset)\n",
    "        \n",
    "        return DataLoader(self.dataset,\n",
    "                         #sampler=train_sampler, \n",
    "                          batch_size=self.batch_size,\n",
    "                          num_workers=min(NUM_PROCESSORS,self.batch_size)\n",
    "                         )\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        \n",
    "        val_sampler = SequentialSampler(self.val_dataset)\n",
    "        \n",
    "        return DataLoader(self.val_dataset,\n",
    "                          sampler=val_sampler, \n",
    "                          batch_size=self.batch_size,\n",
    "                          num_workers=min(NUM_PROCESSORS,self.batch_size)\n",
    "                         )\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        \n",
    "        test_sampler = SequentialSampler(self.test_dataset)\n",
    "        \n",
    "        return DataLoader(self.test_dataset,\n",
    "                          sampler=test_sampler, \n",
    "                          batch_size=self.batch_size,\n",
    "                          num_workers=min(NUM_PROCESSORS,self.batch_size)\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printModelParams(model):\n",
    "    print (model)\n",
    "    # Get all of the model's parameters as a list of tuples.\n",
    "    params = list(model.named_parameters())\n",
    "    print('The model has {:} different named parameters.\\n'.format(len(params)))\n",
    "\n",
    "    print('==== Embedding Layer ====\\n')\n",
    "    for p in params[0:5]:\n",
    "        print(\"{:<55} {:>12}, {}\".format(p[0], str(tuple(p[1].size())),p[1].requires_grad))\n",
    "\n",
    "    print('\\n==== First Transformer ====\\n')\n",
    "    for p in params[5:21]:\n",
    "        print(\"{:<55} {:>12}, {}\".format(p[0], str(tuple(p[1].size())),p[1].requires_grad))\n",
    "\n",
    "    print('\\n==== Output Layer ====\\n')\n",
    "    for p in params[-5:]:\n",
    "        print(\"{:<55} {:>12}, {}\".format(p[0], str(tuple(p[1].size())),p[1].requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_value(model):\n",
    "    params = list(model.named_parameters())\n",
    "    print (params[-1][0],params[-1][1][:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main\n",
    "Two key aspects:\n",
    "\n",
    "- pytorch lightning can add arguments to the parser automatically\n",
    "- you can manually add your own specific arguments.\n",
    "\n",
    "- there is a little more code than seems necessary, because of a particular argument the scheduler\n",
    "  needs. There is currently an open issue on this complication\n",
    "  https://github.com/PyTorchLightning/pytorch-lightning/issues/1038"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic Batching (not used)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "if args.auto_batch>0:    \n",
    "        #init_batch_size=32\n",
    "        init_batch_size=args.auto_batch\n",
    "        tuner = Tuner(trainer)        \n",
    "        assert hasattr(dataProcessor, \"batch_size\")\n",
    "        new_batch_size = tuner.scale_batch_size(model, \n",
    "                                                mode=\"binsearch\", \n",
    "                                                init_val=init_batch_size, \n",
    "                                                max_trials=10,\n",
    "                                                datamodule=dataProcessor,                                        \n",
    "                                               )\n",
    "\n",
    "        print(\"Max batch size: \", new_batch_size)\n",
    "        #dataProcessor.batch_size = new_batch_size\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Configuration to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "def get_configuration():\n",
    "    parser = ArgumentParser()\n",
    "\n",
    "    #parser.add_argument('--pretrained', type=str, default=\"bert-base-uncased\")\n",
    "    #parser.add_argument('--pretrained', type=str, default=\"roberta-base\")\n",
    "    parser.add_argument('--pretrained', type=str, default=\"distilbert-base-uncased\") \n",
    "    parser.add_argument('--epochs', type=int, default=50)\n",
    "    parser.add_argument('--nr_frozen_epochs', type=int, default=5)\n",
    "    parser.add_argument('--training_portion', type=float, default=0.9)\n",
    "    parser.add_argument('--batch_size', type=int, default=32)\n",
    "    parser.add_argument('--auto_batch', type=int, default=-1)\n",
    "    parser.add_argument('--learning_rate', type=float, default=2e-5)\n",
    "    parser.add_argument('--frac', type=float, default=1)\n",
    "    parser.add_argument('--num_gpus', type=int, default=-1)\n",
    "    parser.add_argument('--nodes', type=int, default=1)\n",
    "    parser.add_argument('--parallel_mode', type=str, default=\"dp\", choices=['dp', 'ddp', 'ddp2'])\n",
    "    parser.add_argument('--refresh_rate', type=int, default=1)\n",
    "    parser.add_argument('--check', type=bool, default=True)\n",
    "    parser.add_argument('--rand_dataset', type=str, default=\"dummy\", choices=['temporal','random','dummy'])\n",
    "    \n",
    "    \n",
    "    parser.add_argument('-f') ##dummy for jupyternotebook\n",
    "\n",
    "    # parser = Model.add_model_specific_args(parser) parser = Data.add_model_specific_args(parser)\n",
    "    parser = pl.Trainer.add_argparse_args(parser)\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    print(\"-\"*50)\n",
    "    print(\"BATCH SIZE: \", args.batch_size)\n",
    "    \n",
    "    # start : get training steps\n",
    "    dataProcessor = DataProcessing(args)\n",
    "    dataProcessor.setup()\n",
    "    \n",
    "    args.num_training_steps = len(dataProcessor.train_dataloader())*args.epochs\n",
    "    dict_args = vars(args)\n",
    "    \n",
    "    gpus=-1\n",
    "    if NUM_GPUS>0:\n",
    "        gpus=args.num_gpus        \n",
    "    else:\n",
    "        args.parallel_mode=None\n",
    "        gpus=None\n",
    "    \n",
    "    print(\"USING GPUS:\", gpus)\n",
    "    print(\"-\"*50)\n",
    "    \n",
    "    # saves a file like: my/path/sample-mnist-epoch=02-val_loss=0.32.ckpt\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        monitor='loss_epoch',\n",
    "        dirpath=MODEL_SAVE_DIR,\n",
    "        #filename='{epoch:02d}-{loss:.4f}',\n",
    "        filename=\"CBERT-\"+args.pretrained, #+'-'+str(args.parallel_mode)\n",
    "        save_top_k=1,\n",
    "        mode='min',\n",
    "        save_weights_only=True,\n",
    "        #prefix=\"CBERT-\"+args.pretrained,#+'-'+str(args.parallel_mode),\n",
    "        save_last=True,\n",
    "    )\n",
    "    \n",
    "#     if args.check==False:\n",
    "#         args.checkpoint_callback = False\n",
    "#     elif args.parallel_mode=='dp':\n",
    "#         args.callbacks=[checkpoint_callback]        \n",
    "#     else:\n",
    "#         args.checkpoint_callback = False\n",
    "\n",
    "    args.checkpoint_callback = False\n",
    "    \n",
    "    trainer = pl.Trainer.from_argparse_args(args, \n",
    "                                            gpus=gpus,\n",
    "                                            num_nodes=args.nodes, \n",
    "                                            accelerator=args.parallel_mode,\n",
    "                                            max_epochs=args.epochs, \n",
    "                                            gradient_clip_val=1.0,                                            \n",
    "                                            logger=False,\n",
    "                                            progress_bar_refresh_rate=args.refresh_rate,\n",
    "                                            profiler='simple', #'simple',\n",
    "                                            default_root_dir=MODEL_SAVE_DIR,                                            \n",
    "                                            deterministic=True,\n",
    "                                           )\n",
    "\n",
    "    return trainer, dataProcessor, args, dict_args\n",
    "\n",
    "# trainer, dataProcessor, args, dict_args = get_configuration()\n",
    "# next(iter(dataProcessor.test_dataloader()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():    \n",
    "    trainer, dataProcessor, args, dict_args = get_configuration()\n",
    "    \n",
    "    model = Model(**dict_args)    \n",
    "    \n",
    "#     printModelParams(model)\n",
    "#     args.early_stop_callback = EarlyStopping('val_loss')\n",
    "    \n",
    "    \n",
    "    print(\"Original weights: \");print_model_value(model)\n",
    "    \n",
    "    t0=time.time()\n",
    "    trainer.fit(model, dataProcessor)\n",
    "    print('Training took: ',time.time()-t0)\n",
    "    \n",
    "    print(\"Trained weights: \");print_model_value(model)\n",
    "    \n",
    "    #if args.parallel_mode!='dp':    \n",
    "    print(\"Saving the last model\")\n",
    "    #MODEL_NAME=MODEL_SAVE_DIR+\"CBERT-\"+args.pretrained+'-'+args.parallel_mode+\".ckpt\"\n",
    "    MODEL_NAME=MODEL_SAVE_DIR+\"CBERT-\"+args.pretrained+\".ckpt\"\n",
    "    trainer.save_checkpoint(MODEL_NAME)\n",
    "\n",
    "    print(\"Testing:....\")\n",
    "    trainer.test(model, dataProcessor.test_dataloader())\n",
    "    \n",
    "    print(\"Training Phase Complete......\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model():\n",
    "    trainer, dataProcessor, args, dict_args = get_configuration()\n",
    "    \n",
    "    #MODEL_NAME=MODEL_SAVE_DIR+\"CBERT-\"+args.pretrained+'-'+args.parallel_mode+\".ckpt\"    \n",
    "    MODEL_NAME=MODEL_SAVE_DIR+\"CBERT-\"+args.pretrained+\".ckpt\"    \n",
    "#     if args.parallel_mode=='dp':\n",
    "#         MODEL_NAME=MODEL_SAVE_DIR+\"CBERT-\"+args.pretrained+'-'+args.parallel_mode+\"-last.ckpt\"\n",
    "    \n",
    "    if os.path.exists(MODEL_NAME): \n",
    "        print('Loading Saved Model: ',MODEL_NAME)        \n",
    "    else: \n",
    "        print(\"File not found: \",MODEL_NAME)\n",
    "        return\n",
    "    \n",
    "    model=None\n",
    "    \n",
    "    if args.parallel_mode!='dp':\n",
    "        model = Model.load_from_checkpoint(MODEL_NAME)\n",
    "    else:\n",
    "        model = Model(**dict_args)\n",
    "        print(\"Original weights: \");print_model_value(model)\n",
    "        checkpoint = torch.load(MODEL_NAME, map_location=lambda storage, loc: storage)\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "    print(\"Loaded weights: \");print_model_value(model)    \n",
    "    trainer.test(model, dataProcessor.test_dataloader())    \n",
    "    print(\"Test Complete......\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "BATCH SIZE:  32\n",
      "PRETRAINED:distilbert-base-uncased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer: <class 'transformers.models.distilbert.tokenization_distilbert_fast.DistilBertTokenizerFast'>\n",
      "USING GPUS: -1\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  <class 'transformers.models.distilbert.modeling_distilbert.DistilBertForMaskedLM'>\n",
      "Original weights: \n",
      "model.vocab_projector.bias tensor([-0.5429, -0.6409, -0.6049, -0.6023], grad_fn=<SliceBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Set SLURM handle signals.\n",
      "\n",
      "  | Name  | Type                  | Params\n",
      "------------------------------------------------\n",
      "0 | model | DistilBertForMaskedLM | 67.0 M\n",
      "------------------------------------------------\n",
      "67.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "67.0 M    Total params\n",
      "267.942   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75b33e04127545d38ba2e5bb53d8c06b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ca7b2599c5d48119d107270ff91f805",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e56701bde58141519b3430a60adbb999",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b086ee4d53ea4bda8300b7978f644303",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57e97fa0cd69420b9aba40a43e5b3543",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30bff7d891e54b2d98dd1c21c6a6b322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3b26de56a0c4ee5b4d4d671033d83f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57c3641df9c34b85ac34abd4122b6490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dc752d728584f06bbc13ae3bc977ccd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79b3afa9d25c4d90950665b33b82bfdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cee6985abde49a0a6debd0bd0ab5628",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "894ef3d3246f4f8d9ad2c9da20e308d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89b35fef807e47bdb68d3813158785a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a48a1e081e4a4107ae28a6f215fb1c8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf774398b4de43c6b770ae9015847e50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "671549727cfd464bb0aeda94429ca5a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86d919ee5f9a4d0ba43364748b7a7dd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d34b50dada0d4a1e8e1c10492eeb2f5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "355389877add487b9ba1316b8e3ff777",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dbd3e432296424085bd19002d4f392f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fef8c16db9074101982e62cf12744b56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "409c6ec7ba2148ff86acbdc2bac1d873",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a17974bd29b4f9fac2cfacefa261df2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbd86c5a16f44d5db1d1ceafbb6426a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f0598f5466d48f1abff92d47d9ed28d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aa9df9f91ed43a289ad153867c3fff2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e4deac5002d4d0a8bbfbb658b9110eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05a7e86deed74a67b892b6caf15355d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e285204be8d2493e972694f45ff51e6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4a26991c61145fe851f589c3c0df8b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "849ea2ac228a435da40117b9c9af223d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0620fa00fe54a5bbf5c007330d073f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79c1d8752d6045feb0c6b50285e7718b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5516b1065fcf455181adbb27edde69f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e19ed4205b141e29d02a4f00cfd64bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84206c3ba1e84e3d9206f3be3f6f81e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87b4afa005d94402aaac583d686840d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "943ffd69533d47c48740e279662cf3ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d8672bf140f4f66a17bc708fb37382e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b105a388724142b69347a8a85a2730a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3058cb2644c9437c92a1e57893cd9a97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7184eeaa8458440b91d1e142447c1c93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b02a1593899405899bbe58fd784de0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a72f58099c14171b403350b95e6b39a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bbda1ac303c46cb81dabe3a519ccef8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf6d1950c3354f9e96156f3f1fb721ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4d0d71566e84a7aa356e88050af899c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d8688f8ef354e8fb394c98b52443b5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6193a5aabaf4c9cb53ecc08cc85af8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c711e10a9ca40f5b841bd33e697afe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87a1e7335ea4426ea80e1af32ee78b87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81393e080ff942d091e43ff7610cd531",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FIT Profiler Report\n",
      "\n",
      "Action                             \t|  Mean duration (s)\t|Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total                              \t|  -              \t|_              \t|  129.35         \t|  100 %          \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------\n",
      "run_training_epoch                 \t|  2.1097         \t|50             \t|  105.48         \t|  81.55          \t|\n",
      "get_train_batch                    \t|  0.9597         \t|50             \t|  47.985         \t|  37.097         \t|\n",
      "evaluation_step_and_end            \t|  0.13524        \t|51             \t|  6.8972         \t|  5.3322         \t|\n",
      "validation_step                    \t|  0.13461        \t|51             \t|  6.8654         \t|  5.3076         \t|\n",
      "run_training_batch                 \t|  0.091233       \t|50             \t|  4.5616         \t|  3.5266         \t|\n",
      "optimizer_step_and_closure_0       \t|  0.088693       \t|50             \t|  4.4346         \t|  3.4284         \t|\n",
      "training_step_and_backward         \t|  0.079167       \t|50             \t|  3.9583         \t|  3.0602         \t|\n",
      "backward                           \t|  0.052252       \t|50             \t|  2.6126         \t|  2.0198         \t|\n",
      "model_forward                      \t|  0.025255       \t|50             \t|  1.2627         \t|  0.97621        \t|\n",
      "training_step                      \t|  0.024606       \t|50             \t|  1.2303         \t|  0.95112        \t|\n",
      "on_validation_start                \t|  0.022462       \t|51             \t|  1.1455         \t|  0.88561        \t|\n",
      "on_validation_end                  \t|  0.0031279      \t|51             \t|  0.15952        \t|  0.12333        \t|\n",
      "on_validation_batch_end            \t|  0.003037       \t|51             \t|  0.15489        \t|  0.11974        \t|\n",
      "on_train_batch_end                 \t|  0.002977       \t|50             \t|  0.14885        \t|  0.11507        \t|\n",
      "on_train_epoch_start               \t|  0.0017944      \t|50             \t|  0.089721       \t|  0.069363       \t|\n",
      "on_train_start                     \t|  0.037306       \t|1              \t|  0.037306       \t|  0.028841       \t|\n",
      "cache_result                       \t|  3.0868e-05     \t|915            \t|  0.028244       \t|  0.021835       \t|\n",
      "validation_step_end                \t|  0.0001371      \t|51             \t|  0.0069923      \t|  0.0054057      \t|\n",
      "on_validation_batch_start          \t|  0.00012075     \t|51             \t|  0.0061584      \t|  0.0047611      \t|\n",
      "training_step_end                  \t|  0.00010073     \t|50             \t|  0.0050367      \t|  0.0038938      \t|\n",
      "on_train_epoch_end                 \t|  9.857e-05      \t|50             \t|  0.0049285      \t|  0.0038102      \t|\n",
      "on_batch_start                     \t|  6.0235e-05     \t|50             \t|  0.0030118      \t|  0.0023284      \t|\n",
      "on_train_batch_start               \t|  4.7401e-05     \t|50             \t|  0.00237        \t|  0.0018323      \t|\n",
      "on_after_backward                  \t|  3.8116e-05     \t|50             \t|  0.0019058      \t|  0.0014734      \t|\n",
      "on_epoch_start                     \t|  1.6986e-05     \t|101            \t|  0.0017156      \t|  0.0013263      \t|\n",
      "on_epoch_end                       \t|  1.4235e-05     \t|101            \t|  0.0014377      \t|  0.0011115      \t|\n",
      "on_before_zero_grad                \t|  2.7302e-05     \t|50             \t|  0.0013651      \t|  0.0010554      \t|\n",
      "on_batch_end                       \t|  2.2224e-05     \t|50             \t|  0.0011112      \t|  0.00085907     \t|\n",
      "on_validation_epoch_end            \t|  1.9424e-05     \t|51             \t|  0.0009906      \t|  0.00076583     \t|\n",
      "on_train_end                       \t|  0.00085565     \t|1              \t|  0.00085565     \t|  0.0006615      \t|\n",
      "on_validation_epoch_start          \t|  1.3372e-05     \t|51             \t|  0.00068198     \t|  0.00052724     \t|\n",
      "on_fit_start                       \t|  5.174e-05      \t|1              \t|  5.174e-05      \t|  4e-05          \t|\n",
      "on_train_dataloader                \t|  2.9028e-05     \t|1              \t|  2.9028e-05     \t|  2.2442e-05     \t|\n",
      "on_before_accelerator_backend_setup\t|  1.4256e-05     \t|1              \t|  1.4256e-05     \t|  1.1021e-05     \t|\n",
      "on_val_dataloader                  \t|  1.0203e-05     \t|1              \t|  1.0203e-05     \t|  7.8876e-06     \t|\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took:  127.98507070541382\n",
      "Trained weights: \n",
      "model.vocab_projector.bias tensor([-0.5429, -0.6409, -0.6049, -0.6024], grad_fn=<SliceBackward>)\n",
      "Saving the last model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing:....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c299d5e7640f4d5bb2e52d4141e68794",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST Profiler Report\n",
      "\n",
      "Action                             \t|  Mean duration (s)\t|Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total                              \t|  -              \t|_              \t|  133.44         \t|  100 %          \t|\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "run_training_epoch                 \t|  2.1097         \t|50             \t|  105.48         \t|  79.051         \t|\n",
      "get_train_batch                    \t|  0.9597         \t|50             \t|  47.985         \t|  35.96          \t|\n",
      "evaluation_step_and_end            \t|  0.13379        \t|52             \t|  6.9571         \t|  5.2137         \t|\n",
      "validation_step                    \t|  0.13461        \t|51             \t|  6.8654         \t|  5.1449         \t|\n",
      "run_training_batch                 \t|  0.091233       \t|50             \t|  4.5616         \t|  3.4185         \t|\n",
      "optimizer_step_and_closure_0       \t|  0.088693       \t|50             \t|  4.4346         \t|  3.3233         \t|\n",
      "training_step_and_backward         \t|  0.079167       \t|50             \t|  3.9583         \t|  2.9664         \t|\n",
      "backward                           \t|  0.052252       \t|50             \t|  2.6126         \t|  1.9579         \t|\n",
      "model_forward                      \t|  0.025255       \t|50             \t|  1.2627         \t|  0.94629        \t|\n",
      "training_step                      \t|  0.024606       \t|50             \t|  1.2303         \t|  0.92198        \t|\n",
      "on_validation_start                \t|  0.022462       \t|51             \t|  1.1455         \t|  0.85847        \t|\n",
      "on_validation_end                  \t|  0.0031279      \t|51             \t|  0.15952        \t|  0.11955        \t|\n",
      "on_validation_batch_end            \t|  0.003037       \t|51             \t|  0.15489        \t|  0.11607        \t|\n",
      "on_train_batch_end                 \t|  0.002977       \t|50             \t|  0.14885        \t|  0.11155        \t|\n",
      "on_train_epoch_start               \t|  0.0017944      \t|50             \t|  0.089721       \t|  0.067237       \t|\n",
      "test_step                          \t|  0.058832       \t|1              \t|  0.058832       \t|  0.044089       \t|\n",
      "on_train_start                     \t|  0.037306       \t|1              \t|  0.037306       \t|  0.027957       \t|\n",
      "cache_result                       \t|  3.0813e-05     \t|928            \t|  0.028595       \t|  0.021429       \t|\n",
      "on_test_start                      \t|  0.022824       \t|1              \t|  0.022824       \t|  0.017104       \t|\n",
      "validation_step_end                \t|  0.0001371      \t|51             \t|  0.0069923      \t|  0.0052401      \t|\n",
      "on_validation_batch_start          \t|  0.00012075     \t|51             \t|  0.0061584      \t|  0.0046152      \t|\n",
      "training_step_end                  \t|  0.00010073     \t|50             \t|  0.0050367      \t|  0.0037745      \t|\n",
      "on_train_epoch_end                 \t|  9.857e-05      \t|50             \t|  0.0049285      \t|  0.0036935      \t|\n",
      "on_batch_start                     \t|  6.0235e-05     \t|50             \t|  0.0030118      \t|  0.002257       \t|\n",
      "on_test_batch_end                  \t|  0.0026125      \t|1              \t|  0.0026125      \t|  0.0019578      \t|\n",
      "on_train_batch_start               \t|  4.7401e-05     \t|50             \t|  0.00237        \t|  0.0017761      \t|\n",
      "on_after_backward                  \t|  3.8116e-05     \t|50             \t|  0.0019058      \t|  0.0014282      \t|\n",
      "on_epoch_start                     \t|  1.698e-05      \t|102            \t|  0.001732       \t|  0.001298       \t|\n",
      "on_epoch_end                       \t|  1.4234e-05     \t|102            \t|  0.0014518      \t|  0.001088       \t|\n",
      "on_before_zero_grad                \t|  2.7302e-05     \t|50             \t|  0.0013651      \t|  0.001023       \t|\n",
      "on_batch_end                       \t|  2.2224e-05     \t|50             \t|  0.0011112      \t|  0.00083275     \t|\n",
      "on_validation_epoch_end            \t|  1.9424e-05     \t|51             \t|  0.0009906      \t|  0.00074236     \t|\n",
      "on_train_end                       \t|  0.00085565     \t|1              \t|  0.00085565     \t|  0.00064123     \t|\n",
      "on_test_end                        \t|  0.00082346     \t|1              \t|  0.00082346     \t|  0.00061711     \t|\n",
      "on_validation_epoch_start          \t|  1.3372e-05     \t|51             \t|  0.00068198     \t|  0.00051108     \t|\n",
      "on_test_batch_start                \t|  0.00011573     \t|1              \t|  0.00011573     \t|  8.6725e-05     \t|\n",
      "test_step_end                      \t|  0.0001104      \t|1              \t|  0.0001104      \t|  8.2736e-05     \t|\n",
      "on_fit_start                       \t|  5.174e-05      \t|1              \t|  5.174e-05      \t|  3.8774e-05     \t|\n",
      "on_fit_end                         \t|  4.5601e-05     \t|1              \t|  4.5601e-05     \t|  3.4174e-05     \t|\n",
      "on_before_accelerator_backend_setup\t|  2.1809e-05     \t|2              \t|  4.3618e-05     \t|  3.2688e-05     \t|\n",
      "on_train_dataloader                \t|  2.9028e-05     \t|1              \t|  2.9028e-05     \t|  2.1754e-05     \t|\n",
      "on_test_epoch_end                  \t|  1.8757e-05     \t|1              \t|  1.8757e-05     \t|  1.4056e-05     \t|\n",
      "on_test_dataloader                 \t|  1.7815e-05     \t|1              \t|  1.7815e-05     \t|  1.3351e-05     \t|\n",
      "on_test_epoch_start                \t|  1.255e-05      \t|1              \t|  1.255e-05      \t|  9.4047e-06     \t|\n",
      "on_val_dataloader                  \t|  1.0203e-05     \t|1              \t|  1.0203e-05     \t|  7.6459e-06     \t|\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_loss': 0.22846554219722748}\n",
      "--------------------------------------------------------------------------------\n",
      "Training Phase Complete......\n",
      "--------------------------------------------------\n",
      "BATCH SIZE:  32\n",
      "PRETRAINED:distilbert-base-uncased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/das90/.conda/envs/cent7/2020.11-py38/py38cu11/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:360: UserWarning: Checkpoint directory ./Results/NVD/Model/ exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer: <class 'transformers.models.distilbert.tokenization_distilbert_fast.DistilBertTokenizerFast'>\n",
      "USING GPUS: -1\n",
      "--------------------------------------------------\n",
      "Loading Saved Model:  ./Results/NVD/Model/CBERT-distilbert-base-uncased.ckpt\n",
      "Model:  <class 'transformers.models.distilbert.modeling_distilbert.DistilBertForMaskedLM'>\n",
      "Original weights: \n",
      "model.vocab_projector.bias tensor([-0.5429, -0.6409, -0.6049, -0.6023], grad_fn=<SliceBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded weights: \n",
      "model.vocab_projector.bias tensor([-0.5429, -0.6409, -0.6049, -0.6024], grad_fn=<SliceBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1db1be3fc604d7a9c8d839b1300e6bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST Profiler Report\n",
      "\n",
      "Action                             \t|  Mean duration (s)\t|Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total                              \t|  -              \t|_              \t|  3.0437         \t|  100 %          \t|\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "evaluation_step_and_end            \t|  0.062497       \t|1              \t|  0.062497       \t|  2.0533         \t|\n",
      "test_step                          \t|  0.061709       \t|1              \t|  0.061709       \t|  2.0275         \t|\n",
      "on_test_start                      \t|  0.022419       \t|1              \t|  0.022419       \t|  0.73657        \t|\n",
      "on_test_batch_end                  \t|  0.0029384      \t|1              \t|  0.0029384      \t|  0.096543       \t|\n",
      "on_test_end                        \t|  0.00087652     \t|1              \t|  0.00087652     \t|  0.028798       \t|\n",
      "cache_result                       \t|  3.6947e-05     \t|11             \t|  0.00040642     \t|  0.013353       \t|\n",
      "test_step_end                      \t|  0.00024234     \t|1              \t|  0.00024234     \t|  0.0079622      \t|\n",
      "on_test_batch_start                \t|  0.0001651      \t|1              \t|  0.0001651      \t|  0.0054242      \t|\n",
      "on_before_accelerator_backend_setup\t|  3.8364e-05     \t|1              \t|  3.8364e-05     \t|  0.0012604      \t|\n",
      "on_test_epoch_end                  \t|  2.8647e-05     \t|1              \t|  2.8647e-05     \t|  0.00094121     \t|\n",
      "on_test_dataloader                 \t|  2.1445e-05     \t|1              \t|  2.1445e-05     \t|  0.00070456     \t|\n",
      "on_epoch_start                     \t|  1.9952e-05     \t|1              \t|  1.9952e-05     \t|  0.00065551     \t|\n",
      "on_test_epoch_start                \t|  1.5777e-05     \t|1              \t|  1.5777e-05     \t|  0.00051834     \t|\n",
      "on_epoch_end                       \t|  1.4313e-05     \t|1              \t|  1.4313e-05     \t|  0.00047027     \t|\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_loss': 2.5547971725463867}\n",
      "--------------------------------------------------------------------------------\n",
      "Test Complete......\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    train_model()\n",
    "    test_model()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
